{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b15493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (1.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "084749c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (3.0.0)\n",
      "Collecting flask-pymongo\n",
      "  Downloading Flask_PyMongo-2.3.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting folium\n",
      "  Downloading folium-0.15.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting gevent-websocket\n",
      "  Downloading gevent_websocket-0.10.1-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from flask) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from flask) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from flask) (1.6.3)\n",
      "Collecting PyMongo>=3.3 (from flask-pymongo)\n",
      "  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting branca>=0.6.0 (from folium)\n",
      "  Downloading branca-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from folium) (1.26.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from folium) (2.31.0)\n",
      "Requirement already satisfied: xyzservices in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from folium) (2023.10.1)\n",
      "Requirement already satisfied: gevent in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from gevent-websocket) (23.9.0.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from PyMongo>=3.3->flask-pymongo)\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: zope.event in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from gevent->gevent-websocket) (5.0)\n",
      "Requirement already satisfied: zope.interface in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from gevent->gevent-websocket) (6.1)\n",
      "Requirement already satisfied: greenlet>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from gevent->gevent-websocket) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->folium) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->folium) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->folium) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->folium) (2023.7.22)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from zope.event->gevent->gevent-websocket) (68.2.2)\n",
      "Downloading folium-0.15.1-py2.py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.0/97.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading branca-0.7.0-py3-none-any.whl (25 kB)\n",
      "Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dnspython, PyMongo, branca, gevent-websocket, folium, flask-pymongo\n",
      "Successfully installed PyMongo-4.6.1 branca-0.7.0 dnspython-2.4.2 flask-pymongo-2.3.0 folium-0.15.1 gevent-websocket-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install flask flask-pymongo folium gevent-websocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0658872e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask-ngrok\n",
      "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
      "Requirement already satisfied: flask-cors in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: Flask>=0.8 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from flask-ngrok) (3.0.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from flask-ngrok) (2.31.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Flask>=0.8->flask-ngrok) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Flask>=0.8->flask-ngrok) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Flask>=0.8->flask-ngrok) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Flask>=0.8->flask-ngrok) (1.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->flask-ngrok) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->flask-ngrok) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->flask-ngrok) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->flask-ngrok) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (2.1.3)\n",
      "Installing collected packages: flask-ngrok\n",
      "Successfully installed flask-ngrok-0.0.25\n"
     ]
    }
   ],
   "source": [
    "!pip install flask-ngrok flask-cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44a5153e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask-socketio\n",
      "  Downloading Flask_SocketIO-5.3.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: Flask>=0.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from flask-socketio) (3.0.0)\n",
      "Collecting python-socketio>=5.0.2 (from flask-socketio)\n",
      "  Downloading python_socketio-5.11.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Flask>=0.9->flask-socketio) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Flask>=0.9->flask-socketio) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Flask>=0.9->flask-socketio) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Flask>=0.9->flask-socketio) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Flask>=0.9->flask-socketio) (1.6.3)\n",
      "Collecting bidict>=0.21.0 (from python-socketio>=5.0.2->flask-socketio)\n",
      "  Downloading bidict-0.22.1-py3-none-any.whl (35 kB)\n",
      "Collecting python-engineio>=4.8.0 (from python-socketio>=5.0.2->flask-socketio)\n",
      "  Downloading python_engineio-4.8.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask-socketio) (2.1.3)\n",
      "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.8.0->python-socketio>=5.0.2->flask-socketio)\n",
      "  Downloading simple_websocket-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->flask-socketio)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->flask-socketio) (0.14.0)\n",
      "Downloading Flask_SocketIO-5.3.6-py3-none-any.whl (18 kB)\n",
      "Downloading python_socketio-5.11.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_engineio-4.8.2-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: wsproto, bidict, simple-websocket, python-engineio, python-socketio, flask-socketio\n",
      "Successfully installed bidict-0.22.1 flask-socketio-5.3.6 python-engineio-4.8.2 python-socketio-5.11.0 simple-websocket-1.0.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flask-socketio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9777cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-22.2.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Downloading Faker-22.2.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faker\n",
      "Successfully installed faker-22.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "338d71f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.4.2 pymongo-4.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8745adcf",
   "metadata": {},
   "source": [
    "### Procuring the tarball containing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "274ebb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "prefix = 'diseasePrediction'\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "\n",
    "s3_model_path = f's3://{bucket}/{prefix}/model.tar.gz'\n",
    "\n",
    "\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=s3_model_path,\n",
    "    role=role,\n",
    "    entry_point='inference.py',\n",
    "    framework_version='0.20.0'  # Specify the version of Scikit-learn you used\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e811b1b",
   "metadata": {},
   "source": [
    "### Inference code for loading, input processing and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc6a4d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "try:\n",
    "    import joblib\n",
    "except ImportError:\n",
    "    install('joblib')  # specify the version you need\n",
    "import joblib\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the joblib model from the specified directory.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = joblib.load(f\"{model_dir}/model.joblib\")\n",
    "        logging.info(\"Model loaded successfully.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error in loading model: %s\", e)\n",
    "        raise\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"\n",
    "    Parse input data payload\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if request_content_type == \"text/csv\":\n",
    "            data = np.genfromtxt(request_body.splitlines(), delimiter=',')\n",
    "            logging.info(\"Input data processed successfully.\")\n",
    "            return data.reshape(1, -1)  # Reshape if necessary\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported content type: {request_content_type}\")\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error in input_fn: %s\", e)\n",
    "        raise\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    Make a prediction using the input data and loaded model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        predictions = model.predict(input_data)\n",
    "        logging.info(\"Prediction successful.\")\n",
    "        return predictions\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error in predict_fn: %s\", e)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b8131",
   "metadata": {},
   "source": [
    "### Deploying the model at an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5788b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "# Choose an appropriate instance type based on your model's size and inference load\n",
    "instance_type = 'ml.t2.xlarge' \n",
    "\n",
    "# Deploy the model\n",
    "predictor = sklearn_model.deploy(\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name='Entry44'\n",
    "    # Choose a unique name for your endpoint\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2224a2",
   "metadata": {},
   "source": [
    "### Randomly generating values to make prediction at the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2533f633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[15.0, 36.0]]\n",
      "Predictions: [[15.0, 4.0]]\n",
      "Predictions: [[15.0, 16.0]]\n",
      "Predictions: [[16.0, -1.0]]\n",
      "Predictions: [[16.0, 43.0]]\n",
      "Predictions: [[7.0, 4.0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Add a delay before the next iteration (e.g., 10 seconds)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "# Define the list of column names (replace with your actual column names)\n",
    "all_column_names = [\n",
    "    'itching', 'skin_rash', 'nodal_skin_eruptions', 'continuous_sneezing', 'shivering', 'chills', 'joint_pain',\n",
    "    'stomach_pain', 'acidity', 'ulcers_on_tongue', 'muscle_wasting', 'vomiting', 'burning_micturition',\n",
    "    'spotting_ urination', 'fatigue', 'weight_gain', 'anxiety', 'cold_hands_and_feets', 'mood_swings', 'weight_loss',\n",
    "    'restlessness', 'lethargy', 'patches_in_throat', 'irregular_sugar_level', 'cough', 'high_fever', 'sunken_eyes',\n",
    "    'breathlessness', 'sweating', 'dehydration', 'indigestion', 'headache', 'yellowish_skin', 'dark_urine', 'nausea',\n",
    "    'loss_of_appetite', 'pain_behind_the_eyes', 'back_pain', 'constipation', 'abdominal_pain', 'diarrhoea', 'mild_fever',\n",
    "    'yellow_urine', 'yellowing_of_eyes', 'acute_liver_failure', 'fluid_overload', 'swelling_of_stomach',\n",
    "    'swelled_lymph_nodes', 'malaise', 'blurred_and_distorted_vision', 'phlegm', 'throat_irritation', 'redness_of_eyes',\n",
    "    'sinus_pressure', 'runny_nose', 'congestion', 'chest_pain', 'weakness_in_limbs', 'fast_heart_rate',\n",
    "    'pain_during_bowel_movements', 'pain_in_anal_region', 'bloody_stool', 'irritation_in_anus', 'neck_pain', 'dizziness',\n",
    "    'cramps', 'bruising', 'obesity', 'swollen_legs', 'swollen_blood_vessels', 'puffy_face_and_eyes', 'enlarged_thyroid',\n",
    "    'brittle_nails', 'swollen_extremeties', 'excessive_hunger', 'extra_marital_contacts', 'drying_and_tingling_lips',\n",
    "    'slurred_speech', 'knee_pain', 'hip_joint_pain', 'muscle_weakness', 'stiff_neck', 'swelling_joints',\n",
    "    'movement_stiffness', 'spinning_movements', 'loss_of_balance', 'unsteadiness', 'weakness_of_one_body_side',\n",
    "    'loss_of_smell', 'bladder_discomfort', 'foul_smell_of urine', 'continuous_feel_of_urine', 'passage_of_gases',\n",
    "    'internal_itching', 'toxic_look_(typhos)', 'depression', 'irritability', 'muscle_pain', 'altered_sensorium',\n",
    "    'red_spots_over_body', 'belly_pain', 'abnormal_menstruation', 'dischromic _patches', 'watering_from_eyes',\n",
    "    'increased_appetite', 'polyuria', 'family_history', 'mucoid_sputum', 'rusty_sputum', 'lack_of_concentration',\n",
    "    'visual_disturbances', 'receiving_blood_transfusion', 'receiving_unsterile_injections', 'coma', 'stomach_bleeding',\n",
    "    'distention_of_abdomen', 'history_of_alcohol_consumption', 'blood_in_sputum', 'prominent_veins_on_calf',\n",
    "    'palpitations', 'painful_walking', 'pus_filled_pimples', 'blackheads', 'scurring', 'skin_peeling',\n",
    "    'silver_like_dusting', 'small_dents_in_nails', 'inflammatory_nails', 'blister', 'red_sore_around_nose',\n",
    "    'yellow_crust_ooze', 'District'\n",
    "]\n",
    "\n",
    "columns_to_exclude = ['medicine_name', 'disease']\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Remove excluded columns from the list\n",
    "    remaining_columns = [col for col in all_column_names if col not in columns_to_exclude]\n",
    "\n",
    "    # Initialize an empty DataFrame with a single row\n",
    "    data = pd.DataFrame(columns=remaining_columns)\n",
    "\n",
    "    # Generate random binary values for each remaining column in the single row\n",
    "    for column_name in remaining_columns:\n",
    "        random_binary_value = random.choice([0, 1])\n",
    "        data.at[0, column_name] = random_binary_value\n",
    "\n",
    "    # Serialize the data to CSV format and encode to bytes\n",
    "    csv_data = data.to_csv(index=False, header=False)\n",
    "    csv_data_bytes = csv_data.encode()\n",
    "\n",
    "    # Create a SageMaker runtime client\n",
    "    sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "    # Specify your SageMaker endpoint name\n",
    "    endpoint_name = 'Entry44'  # Replace with your endpoint name\n",
    "\n",
    "    # Send the CSV data to the SageMaker endpoint for prediction\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='text/csv',\n",
    "        Body=csv_data_bytes\n",
    "    )\n",
    "\n",
    "    # Parse the prediction result from the response\n",
    "    prediction = json.loads(response['Body'].read().decode())\n",
    "\n",
    "    print(f\"Predictions: {prediction}\")\n",
    "\n",
    "    # Add a delay before the next iteration (e.g., 10 seconds)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6e4e3973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17.0, -1.0, 34.0]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce7ed95",
   "metadata": {},
   "source": [
    "### Loading the mapped decoded values of the label encoded features from mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b8ab3c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (404) when calling the HeadObject operation: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m object_key \u001b[38;5;129;01min\u001b[39;00m object_keys:\n\u001b[1;32m     19\u001b[0m     local_file_path \u001b[38;5;241m=\u001b[39m object_key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Extract the file name from the object key\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     \u001b[43ms3_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Now the files are downloaded to your Jupyter notebook's current directory\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/boto3/s3/inject.py:192\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03mUsage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    transfer.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/boto3/s3/transfer.py:405\u001b[0m, in \u001b[0;36mS3Transfer.download_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    401\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mdownload(\n\u001b[1;32m    402\u001b[0m     bucket, key, filename, extra_args, subscribers\n\u001b[1;32m    403\u001b[0m )\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# their own retries.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/s3transfer/futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/s3transfer/futures.py:266\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/s3transfer/tasks.py:269\u001b[0m, in \u001b[0;36mSubmissionTask._main\u001b[0;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_coordinator\u001b[38;5;241m.\u001b[39mset_status_to_running()\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# Call the submit method to start submitting tasks to execute the\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# transfer.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_submit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# If there was an exception raised during the submission of task\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# there is a chance that the final task that signals if a transfer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# Set the exception, that caused the process to fail.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_and_set_exception(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/s3transfer/download.py:354\u001b[0m, in \u001b[0;36mDownloadSubmissionTask._submit\u001b[0;34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m:param client: The client associated with the transfer manager\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    downloading streams\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transfer_future\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39msize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;66;03m# If a size was not provided figure out the size for the\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;66;03m# user.\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     transfer_future\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mprovide_transfer_size(\n\u001b[1;32m    360\u001b[0m         response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContentLength\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    361\u001b[0m     )\n\u001b[1;32m    363\u001b[0m download_output_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_download_output_manager_cls(\n\u001b[1;32m    364\u001b[0m     transfer_future, osutil\n\u001b[1;32m    365\u001b[0m )(osutil, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_coordinator, io_executor)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/botocore/client.py:553\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m     )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/botocore/client.py:1009\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (404) when calling the HeadObject operation: Not Found"
     ]
    }
   ],
   "source": [
    "# import boto3\n",
    "# import sagemaker\n",
    "\n",
    "# # Create a Boto3 S3 client\n",
    "# s3_client = boto3.client('s3')\n",
    "\n",
    "# # Define your SageMaker session and get the default S3 bucket\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "# bucket_name = sagemaker_session.default_bucket()\n",
    "\n",
    "# # Specify the object keys (file paths) in your S3 bucket\n",
    "# object_keys = [\n",
    "#     'diseasePrediction/disease_mapping.txt',\n",
    "#     'diseasePrediction/medicine_name_mapping.txt'  # Assuming this is a different file\n",
    "# ]\n",
    "\n",
    "# # Download files from S3 to your SageMaker notebook\n",
    "# for object_key in object_keys:\n",
    "#     local_file_path = object_key.split('/')[-1]  # Extract the file name from the object key\n",
    "#     s3_client.download_file(bucket_name, object_key, local_file_path)\n",
    "\n",
    "# # Now the files are downloaded to your Jupyter notebook's current directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af07dd",
   "metadata": {},
   "source": [
    "### Using the decoded values to print the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3776c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted disease is cervical spondylosis. Recommended medicine is: analgesic. The district in Saigon with the highest number of patients suffering from this disease is Tan Phu District\n"
     ]
    }
   ],
   "source": [
    "# Define a function to load label encoder mappings from a text file\n",
    "def load_label_encoder(filename):\n",
    "    mapping = {}\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(': ')\n",
    "            if len(parts) == 2:\n",
    "                label, value = parts\n",
    "                mapping[int(value)] = label\n",
    "    return mapping\n",
    "\n",
    "# Load the saved label encoders for disease, medicine_name, and district\n",
    "disease_mapping = load_label_encoder('disease_mapping.txt')\n",
    "medicine_name_mapping = load_label_encoder('medicine_name_mapping.txt')\n",
    "\n",
    "# Convert the numeric predictions to their corresponding labels\n",
    "numeric_predictions = prediction  # Replace with your actual numeric predictions\n",
    "label_predictions = []\n",
    "\n",
    "for pred in numeric_predictions:\n",
    "    label_disease = disease_mapping.get(int(pred[0]), \"Unknown\")\n",
    "    label_medicine_name = medicine_name_mapping.get(int(pred[1]), \"Unknown\")\n",
    "    label_predictions.append([label_disease, label_district, label_medicine_name])\n",
    "\n",
    "# Now label_predictions contains the corresponding labels for your numeric predictions\n",
    "print(f\"The predicted disease is {label_disease}. Recommended medicine is: {label_medicine_name}. The district in Saigon with the highest number of patients suffering from this disease is {label_district}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd5f80",
   "metadata": {},
   "source": [
    "### Continuoes value generation for presentation(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca9a17a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'row_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 62\u001b[0m\n\u001b[1;32m     56\u001b[0m endpoint_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntry44\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Invoke the endpoint with the CSV data\u001b[39;00m\n\u001b[1;32m     59\u001b[0m response \u001b[38;5;241m=\u001b[39m sagemaker_runtime\u001b[38;5;241m.\u001b[39minvoke_endpoint(\n\u001b[1;32m     60\u001b[0m     EndpointName\u001b[38;5;241m=\u001b[39mendpoint_name,\n\u001b[1;32m     61\u001b[0m     ContentType\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext/csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m---> 62\u001b[0m     Body\u001b[38;5;241m=\u001b[39m\u001b[43mrow_csv\u001b[49m\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Parse the prediction result from the response\u001b[39;00m\n\u001b[1;32m     66\u001b[0m prediction \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'row_csv' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pymongo\n",
    "import time\n",
    "# List of all column names\n",
    "all_column_names = [\n",
    "    'itching', 'skin_rash', 'nodal_skin_eruptions', 'continuous_sneezing', 'shivering', 'chills', 'joint_pain',\n",
    "    'stomach_pain', 'acidity', 'ulcers_on_tongue', 'muscle_wasting', 'vomiting', 'burning_micturition',\n",
    "    'spotting_ urination', 'fatigue', 'weight_gain', 'anxiety', 'cold_hands_and_feets', 'mood_swings', 'weight_loss',\n",
    "    'restlessness', 'lethargy', 'patches_in_throat', 'irregular_sugar_level', 'cough', 'high_fever', 'sunken_eyes',\n",
    "    'breathlessness', 'sweating', 'dehydration', 'indigestion', 'headache', 'yellowish_skin', 'dark_urine', 'nausea',\n",
    "    'loss_of_appetite', 'pain_behind_the_eyes', 'back_pain', 'constipation', 'abdominal_pain', 'diarrhoea', 'mild_fever',\n",
    "    'yellow_urine', 'yellowing_of_eyes', 'acute_liver_failure', 'fluid_overload', 'swelling_of_stomach',\n",
    "    'swelled_lymph_nodes', 'malaise', 'blurred_and_distorted_vision', 'phlegm', 'throat_irritation', 'redness_of_eyes',\n",
    "    'sinus_pressure', 'runny_nose', 'congestion', 'chest_pain', 'weakness_in_limbs', 'fast_heart_rate',\n",
    "    'pain_during_bowel_movements', 'pain_in_anal_region', 'bloody_stool', 'irritation_in_anus', 'neck_pain', 'dizziness',\n",
    "    'cramps', 'bruising', 'obesity', 'swollen_legs', 'swollen_blood_vessels', 'puffy_face_and_eyes', 'enlarged_thyroid',\n",
    "    'brittle_nails', 'swollen_extremeties', 'excessive_hunger', 'extra_marital_contacts', 'drying_and_tingling_lips',\n",
    "    'slurred_speech', 'knee_pain', 'hip_joint_pain', 'muscle_weakness', 'stiff_neck', 'swelling_joints',\n",
    "    'movement_stiffness', 'spinning_movements', 'loss_of_balance', 'unsteadiness', 'weakness_of_one_body_side',\n",
    "    'loss_of_smell', 'bladder_discomfort', 'foul_smell_of urine', 'continuous_feel_of_urine', 'passage_of_gases',\n",
    "    'internal_itching', 'toxic_look_(typhos)', 'depression', 'irritability', 'muscle_pain', 'altered_sensorium',\n",
    "    'red_spots_over_body', 'belly_pain', 'abnormal_menstruation', 'dischromic _patches', 'watering_from_eyes',\n",
    "    'increased_appetite', 'polyuria', 'family_history', 'mucoid_sputum', 'rusty_sputum', 'lack_of_concentration',\n",
    "    'visual_disturbances', 'receiving_blood_transfusion', 'receiving_unsterile_injections', 'coma', 'stomach_bleeding',\n",
    "    'distention_of_abdomen', 'history_of_alcohol_consumption', 'blood_in_sputum', 'prominent_veins_on_calf',\n",
    "    'palpitations', 'painful_walking', 'pus_filled_pimples', 'blackheads', 'scurring', 'skin_peeling',\n",
    "    'silver_like_dusting', 'small_dents_in_nails', 'inflammatory_nails', 'blister', 'red_sore_around_nose',\n",
    "    'yellow_crust_ooze,x,y,z'\n",
    "]\n",
    "\n",
    "mongodb_uri = 'mongodb+srv://saurabh:Solarwind%401@companydata.g6xbxk5.mongodb.net/'\n",
    "# MongoDB database and collection names\n",
    "db_name = 'asm3'\n",
    "\n",
    "\n",
    "# Initialize MongoDB client\n",
    "client = pymongo.MongoClient(mongodb_uri)\n",
    "\n",
    "# Connect to the database\n",
    "db = client[db_name]\n",
    "\n",
    "# Get the collection (create it if it doesn't exist)\n",
    "collection = db[\"result\"]\n",
    "\n",
    "while True:\n",
    "    # Randomly assign binary values (0 or 1) to each column\n",
    "    row_data = [random.choice([0, 1]) for _ in range(len(all_column_names))]\n",
    "\n",
    "    # Convert the row_data list to a dictionary with column names as keys\n",
    "    row_dict = {column_name: column_value for column_name, column_value in zip(all_column_names, row_data)}\n",
    "\n",
    "    # Initialize SageMaker runtime client\n",
    "    sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "    # Specify the SageMaker endpoint name\n",
    "    endpoint_name = 'Entry44'\n",
    "\n",
    "    # Invoke the endpoint with the CSV data\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='text/csv',\n",
    "        Body=row_csv\n",
    "    )\n",
    "\n",
    "    # Parse the prediction result from the response\n",
    "    prediction = json.loads(response['Body'].read().decode())\n",
    "    numeric_predictions = prediction  # Replace with your actual numeric predictions\n",
    "\n",
    "    label_predictions = []\n",
    "\n",
    "    for pred in numeric_predictions:\n",
    "        label_disease = disease_mapping.get(int(pred[0]), \"Unknown\")\n",
    "        label_medicine_name = medicine_name_mapping.get(int(pred[1]), \"Unknown\")\n",
    "        label_predictions.append([label_disease, label_medicine_name])\n",
    "\n",
    "    # Create a document that includes column names, their values, numeric predictions, and label predictions\n",
    "    document = {\n",
    "        **row_dict,\n",
    "        'predicted_disease': label_disease,\n",
    "        'predicted_medicine': label_medicine_name\n",
    "    }\n",
    "\n",
    "    # Insert the document into MongoDB\n",
    "    collection.insert_one(document)\n",
    "\n",
    "    # Now label_predictions contains the corresponding labels for your numeric predictions\n",
    "    print(\"Inserted into MongoDB\")\n",
    "\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0dfb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run backend.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32980be3",
   "metadata": {},
   "source": [
    "### Continuous value generation for presentation(faker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f20942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3270ca90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted $cervical spondylosis_$d1\n",
      "Inserted $cervical spondylosis_$d12\n",
      "Inserted $cervical spondylosis_$Tan Phu District\n",
      "Inserted $cervical spondylosis_$Tan Binh District\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 157\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInserted $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_document[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_disease\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_$\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_document[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistrict\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Wait for 10 seconds\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m \u001b[43mgenerate_and_insert_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 155\u001b[0m, in \u001b[0;36mgenerate_and_insert_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m predicted_values_collection\u001b[38;5;241m.\u001b[39minsert_one(prediction_document)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInserted $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_document[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_disease\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_$\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_document[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistrict\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 155\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pymongo\n",
    "import time\n",
    "import csv\n",
    "from flask_socketio import emit\n",
    "from faker import Faker\n",
    "from faker.providers import DynamicProvider\n",
    "from datetime import datetime, timedelta\n",
    "# List of all column names\n",
    "all_column_names = [\n",
    "    'itching', 'skin_rash', 'nodal_skin_eruptions', 'continuous_sneezing', 'shivering', 'chills', 'joint_pain',\n",
    "    'stomach_pain', 'acidity', 'ulcers_on_tongue', 'muscle_wasting', 'vomiting', 'burning_micturition',\n",
    "    'spotting_ urination', 'fatigue', 'weight_gain', 'anxiety', 'cold_hands_and_feets', 'mood_swings', 'weight_loss',\n",
    "    'restlessness', 'lethargy', 'patches_in_throat', 'irregular_sugar_level', 'cough', 'high_fever', 'sunken_eyes',\n",
    "    'breathlessness', 'sweating', 'dehydration', 'indigestion', 'headache', 'yellowish_skin', 'dark_urine', 'nausea',\n",
    "    'loss_of_appetite', 'pain_behind_the_eyes', 'back_pain', 'constipation', 'abdominal_pain', 'diarrhoea', 'mild_fever',\n",
    "    'yellow_urine', 'yellowing_of_eyes', 'acute_liver_failure', 'fluid_overload', 'swelling_of_stomach',\n",
    "    'swelled_lymph_nodes', 'malaise', 'blurred_and_distorted_vision', 'phlegm', 'throat_irritation', 'redness_of_eyes',\n",
    "    'sinus_pressure', 'runny_nose', 'congestion', 'chest_pain', 'weakness_in_limbs', 'fast_heart_rate',\n",
    "    'pain_during_bowel_movements', 'pain_in_anal_region', 'bloody_stool', 'irritation_in_anus', 'neck_pain', 'dizziness',\n",
    "    'cramps', 'bruising', 'obesity', 'swollen_legs', 'swollen_blood_vessels', 'puffy_face_and_eyes', 'enlarged_thyroid',\n",
    "    'brittle_nails', 'swollen_extremeties', 'excessive_hunger', 'extra_marital_contacts', 'drying_and_tingling_lips',\n",
    "    'slurred_speech', 'knee_pain', 'hip_joint_pain', 'muscle_weakness', 'stiff_neck', 'swelling_joints',\n",
    "    'movement_stiffness', 'spinning_movements', 'loss_of_balance', 'unsteadiness', 'weakness_of_one_body_side',\n",
    "    'loss_of_smell', 'bladder_discomfort', 'foul_smell_of urine', 'continuous_feel_of_urine', 'passage_of_gases',\n",
    "    'internal_itching', 'toxic_look_(typhos)', 'depression', 'irritability', 'muscle_pain', 'altered_sensorium',\n",
    "    'red_spots_over_body', 'belly_pain', 'abnormal_menstruation', 'dischromic _patches', 'watering_from_eyes',\n",
    "    'increased_appetite', 'polyuria', 'family_history', 'mucoid_sputum', 'rusty_sputum', 'lack_of_concentration',\n",
    "    'visual_disturbances', 'receiving_blood_transfusion', 'receiving_unsterile_injections', 'coma', 'stomach_bleeding',\n",
    "    'distention_of_abdomen', 'history_of_alcohol_consumption', 'blood_in_sputum', 'prominent_veins_on_calf',\n",
    "    'palpitations', 'painful_walking', 'pus_filled_pimples', 'blackheads', 'scurring', 'skin_peeling',\n",
    "    'silver_like_dusting', 'small_dents_in_nails', 'inflammatory_nails', 'blister', 'red_sore_around_nose',\n",
    "    'yellow_crust_ooze,x,y,z'\n",
    "]\n",
    "\n",
    "mongodb_uri = 'mongodb+srv://saurabh:Solarwind%401@companydata.g6xbxk5.mongodb.net/'\n",
    "# MongoDB database and collection names\n",
    "db_name = 'asm3'\n",
    "\n",
    "\n",
    "# Initialize MongoDB client\n",
    "client = pymongo.MongoClient(mongodb_uri)\n",
    "\n",
    "# Connect to the database\n",
    "db = client[db_name]\n",
    "\n",
    "# Get the collections (create them if they don't exist)\n",
    "raw_data_collection = db[\"streaming_data\"]\n",
    "predicted_values_collection = db[\"result\"]\n",
    "\n",
    "# Function to read CSV and return a list of rows along with column names\n",
    "def read_csv_to_list(csv_file_path):\n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        columns = next(csv_reader)  # Get column names from the first row\n",
    "        data = [dict(zip(columns, row)) for row in csv_reader]  # Create a dict for each row\n",
    "    return columns, data\n",
    "\n",
    "# Function to generate a random symptom data row\n",
    "def generate_symptom_data():\n",
    "    return {symptom: fake.random.randint(0, 1) for symptom in all_column_names}\n",
    "\n",
    "# Function to assign latitude, longitude, and district\n",
    "def assign_location(district_coordinates):\n",
    "    district = random.choice(list(district_coordinates.keys()))\n",
    "    latitude, longitude = district_coordinates[district]\n",
    "    return district, latitude, longitude\n",
    "\n",
    "# Function to generate and insert data into MongoDB\n",
    "def generate_and_insert_data():\n",
    "    # District Coordinates\n",
    "    district_coordinates = {\n",
    "    'd1': (10.7763897, 106.7011391), 'd2': (10.7763897, 106.7011391),\n",
    "    'd3': (10.7763897, 106.7011391), 'd4': (10.8420693, 106.8277083),\n",
    "    'd5': (10.7763897, 106.7011391), 'd6': (10.7763897, 106.7011391),\n",
    "    'd7': (10.7763897, 106.7011391), 'd8': (10.7763897, 106.7011391),\n",
    "    'd9': (10.7763897, 106.7011391), 'd10': (10.8155799, 106.6257578),\n",
    "    'd11': (10.7008257, 106.7287453), 'd12': (10.815238, 106.6260036),\n",
    "    'Binh Tan District': (10.7703708, 106.5996353),\n",
    "    'Binh Thanh District': (10.8117887, 106.7039109),\n",
    "    'Phu Nhuan District': (10.800981, 106.6794379),\n",
    "    'Tan Binh District': (10.802583, 106.6521157),\n",
    "    'Tan Phu District': (10.7914967, 106.6278431),\n",
    "    'Thu Duc District': (10.82202275, 106.71830155362943)\n",
    "     }\n",
    "        \n",
    "# CSV File Path\n",
    "    csv_file_path = 'dataset_for_simulating_streaming.csv'\n",
    "\n",
    "    # Read the CSV data and get columns\n",
    "    columns, csv_data = read_csv_to_list(csv_file_path)\n",
    "\n",
    "    # Create a Dynamic Provider with the CSV data\n",
    "    class CSVDataProvider(DynamicProvider):\n",
    "        def __init__(self, elements):\n",
    "            super().__init__(provider_name=\"csv_row\", elements=elements)\n",
    "\n",
    "        def generate_csv_data(self):\n",
    "            return self.random_element(self.elements)\n",
    "\n",
    "    # Faker setup\n",
    "    fake = Faker()\n",
    "    csv_data_provider = CSVDataProvider(csv_data)\n",
    "    fake.add_provider(csv_data_provider)\n",
    "\n",
    "    # Function to assign latitude and longitude to a row\n",
    "    def assign_lat_long(district_coordinates):\n",
    "        district = random.choice(list(district_coordinates.keys()))\n",
    "        lat_long = district_coordinates[district]\n",
    "        if isinstance(lat_long, tuple) and len(lat_long) == 2:\n",
    "            return lat_long\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid latitude/longitude data for district {district}\")\n",
    "\n",
    "    # Initial assignment\n",
    "    for row in csv_data:\n",
    "        latitude, longitude = assign_lat_long(district_coordinates)\n",
    "        row['Latitude'], row['Longitude'] = latitude, longitude\n",
    "        row['District'] = [district for district, coords in district_coordinates.items() if coords == (latitude, longitude)][0]\n",
    "\n",
    "    start_time = datetime.now()  # Store the start time\n",
    "\n",
    "    while True:\n",
    "        current_time = datetime.now()\n",
    "\n",
    "        # Check if two hours have passed and update latitude and longitude\n",
    "        if current_time >= start_time + timedelta(hours=2):\n",
    "            for row in csv_data:\n",
    "                latitude, longitude = assign_lat_long(district_coordinates)\n",
    "                row['Latitude'], row['Longitude'] = latitude, longitude\n",
    "                row['District'] = [district for district, coords in district_coordinates.items() if coords == (latitude, longitude)][0]\n",
    "            start_time = current_time  # Reset start time\n",
    "\n",
    "        for csv_row_dict in csv_data:\n",
    "            csv_row_dict['Timestamp'] = current_time\n",
    "\n",
    "            # Remove the '_id' field if it exists in the dictionary\n",
    "            csv_row_dict.pop('_id', None)\n",
    "\n",
    "            # Insert raw data into the 'streaming_data' collection\n",
    "            raw_data_collection.insert_one(csv_row_dict)\n",
    "            \n",
    "            \n",
    "            # Example:\n",
    "            prediction_document = {\n",
    "                **csv_row_dict,\n",
    "                'predicted_disease': label_disease,\n",
    "                'predicted_medicine': label_medicine_name,\n",
    "                'predicted_district': label_district\n",
    "            }\n",
    "            predicted_values_collection.insert_one(prediction_document)\n",
    "\n",
    "            print(f\"Inserted ${prediction_document['predicted_disease']}_${prediction_document['District']}\")\n",
    "\n",
    "            time.sleep(10)  # Wait for 10 seconds\n",
    "\n",
    "generate_and_insert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38258549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pymongo\n",
    "import time\n",
    "import csv\n",
    "from flask_socketio import emit\n",
    "from faker import Faker\n",
    "from faker.providers import DynamicProvider\n",
    "from datetime import datetime, timedelta\n",
    "# List of all column names\n",
    "all_column_names = [\n",
    "    'itching', 'skin_rash', 'nodal_skin_eruptions', 'continuous_sneezing', 'shivering', 'chills', 'joint_pain',\n",
    "    'stomach_pain', 'acidity', 'ulcers_on_tongue', 'muscle_wasting', 'vomiting', 'burning_micturition',\n",
    "    'spotting_ urination', 'fatigue', 'weight_gain', 'anxiety', 'cold_hands_and_feets', 'mood_swings', 'weight_loss',\n",
    "    'restlessness', 'lethargy', 'patches_in_throat', 'irregular_sugar_level', 'cough', 'high_fever', 'sunken_eyes',\n",
    "    'breathlessness', 'sweating', 'dehydration', 'indigestion', 'headache', 'yellowish_skin', 'dark_urine', 'nausea',\n",
    "    'loss_of_appetite', 'pain_behind_the_eyes', 'back_pain', 'constipation', 'abdominal_pain', 'diarrhoea', 'mild_fever',\n",
    "    'yellow_urine', 'yellowing_of_eyes', 'acute_liver_failure', 'fluid_overload', 'swelling_of_stomach',\n",
    "    'swelled_lymph_nodes', 'malaise', 'blurred_and_distorted_vision', 'phlegm', 'throat_irritation', 'redness_of_eyes',\n",
    "    'sinus_pressure', 'runny_nose', 'congestion', 'chest_pain', 'weakness_in_limbs', 'fast_heart_rate',\n",
    "    'pain_during_bowel_movements', 'pain_in_anal_region', 'bloody_stool', 'irritation_in_anus', 'neck_pain', 'dizziness',\n",
    "    'cramps', 'bruising', 'obesity', 'swollen_legs', 'swollen_blood_vessels', 'puffy_face_and_eyes', 'enlarged_thyroid',\n",
    "    'brittle_nails', 'swollen_extremeties', 'excessive_hunger', 'extra_marital_contacts', 'drying_and_tingling_lips',\n",
    "    'slurred_speech', 'knee_pain', 'hip_joint_pain', 'muscle_weakness', 'stiff_neck', 'swelling_joints',\n",
    "    'movement_stiffness', 'spinning_movements', 'loss_of_balance', 'unsteadiness', 'weakness_of_one_body_side',\n",
    "    'loss_of_smell', 'bladder_discomfort', 'foul_smell_of urine', 'continuous_feel_of_urine', 'passage_of_gases',\n",
    "    'internal_itching', 'toxic_look_(typhos)', 'depression', 'irritability', 'muscle_pain', 'altered_sensorium',\n",
    "    'red_spots_over_body', 'belly_pain', 'abnormal_menstruation', 'dischromic _patches', 'watering_from_eyes',\n",
    "    'increased_appetite', 'polyuria', 'family_history', 'mucoid_sputum', 'rusty_sputum', 'lack_of_concentration',\n",
    "    'visual_disturbances', 'receiving_blood_transfusion', 'receiving_unsterile_injections', 'coma', 'stomach_bleeding',\n",
    "    'distention_of_abdomen', 'history_of_alcohol_consumption', 'blood_in_sputum', 'prominent_veins_on_calf',\n",
    "    'palpitations', 'painful_walking', 'pus_filled_pimples', 'blackheads', 'scurring', 'skin_peeling',\n",
    "    'silver_like_dusting', 'small_dents_in_nails', 'inflammatory_nails', 'blister', 'red_sore_around_nose',\n",
    "    'yellow_crust_ooze,x,y,z'\n",
    "]\n",
    "\n",
    "mongodb_uri = 'mongodb+srv://saurabh:Solarwind%401@companydata.g6xbxk5.mongodb.net/'\n",
    "# MongoDB database and collection names\n",
    "db_name = 'asm3'\n",
    "\n",
    "\n",
    "# Initialize MongoDB client\n",
    "client = pymongo.MongoClient(mongodb_uri)\n",
    "\n",
    "# Connect to the database\n",
    "db = client[db_name]\n",
    "\n",
    "# Get the collections (create them if they don't exist)\n",
    "raw_data_collection = db[\"streaming_data\"]\n",
    "predicted_values_collection = db[\"result\"]\n",
    "\n",
    "# Function to read CSV and return a list of rows along with column names\n",
    "def read_csv_to_list(csv_file_path):\n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        columns = next(csv_reader)  # Get column names from the first row\n",
    "        data = [dict(zip(columns, row)) for row in csv_reader]  # Create a dict for each row\n",
    "    return columns, data\n",
    "\n",
    "# Function to generate a random symptom data row\n",
    "def generate_symptom_data():\n",
    "    return {symptom: fake.random.randint(0, 1) for symptom in all_column_names}\n",
    "\n",
    "# Function to assign latitude, longitude, and district\n",
    "def assign_location(district_coordinates):\n",
    "    district = random.choice(list(district_coordinates.keys()))\n",
    "    latitude, longitude = district_coordinates[district]\n",
    "    return district, latitude, longitude\n",
    "\n",
    "# Function to generate and insert data into MongoDB\n",
    "def generate_and_insert_data():\n",
    "    # District Coordinates\n",
    "    district_coordinates = {\n",
    "    'd1': (10.7763897, 106.7011391), 'd2': (10.7763897, 106.7011391),\n",
    "    'd3': (10.7763897, 106.7011391), 'd4': (10.8420693, 106.8277083),\n",
    "    'd5': (10.7763897, 106.7011391), 'd6': (10.7763897, 106.7011391),\n",
    "    'd7': (10.7763897, 106.7011391), 'd8': (10.7763897, 106.7011391),\n",
    "    'd9': (10.7763897, 106.7011391), 'd10': (10.8155799, 106.6257578),\n",
    "    'd11': (10.7008257, 106.7287453), 'd12': (10.815238, 106.6260036),\n",
    "    'Binh Tan District': (10.7703708, 106.5996353),\n",
    "    'Binh Thanh District': (10.8117887, 106.7039109),\n",
    "    'Phu Nhuan District': (10.800981, 106.6794379),\n",
    "    'Tan Binh District': (10.802583, 106.6521157),\n",
    "    'Tan Phu District': (10.7914967, 106.6278431),\n",
    "    'Thu Duc District': (10.82202275, 106.71830155362943)\n",
    "     }\n",
    "        \n",
    "# CSV File Path\n",
    "    csv_file_path = 'dataset_for_simulating_streaming.csv'\n",
    "\n",
    "    # Read the CSV data and get columns\n",
    "    columns, csv_data = read_csv_to_list(csv_file_path)\n",
    "\n",
    "    # Create a Dynamic Provider with the CSV data\n",
    "    class CSVDataProvider(DynamicProvider):\n",
    "        def __init__(self, elements):\n",
    "            super().__init__(provider_name=\"csv_row\", elements=elements)\n",
    "\n",
    "        def generate_csv_data(self):\n",
    "            return self.random_element(self.elements)\n",
    "\n",
    "    # Faker setup\n",
    "    fake = Faker()\n",
    "    csv_data_provider = CSVDataProvider(csv_data)\n",
    "    fake.add_provider(csv_data_provider)\n",
    "\n",
    "    # Function to assign latitude and longitude to a row\n",
    "    def assign_lat_long(district_coordinates):\n",
    "        district = random.choice(list(district_coordinates.keys()))\n",
    "        lat_long = district_coordinates[district]\n",
    "        if isinstance(lat_long, tuple) and len(lat_long) == 2:\n",
    "            return lat_long\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid latitude/longitude data for district {district}\")\n",
    "\n",
    "    # Initial assignment\n",
    "    for row in csv_data:\n",
    "        latitude, longitude = assign_lat_long(district_coordinates)\n",
    "        row['Latitude'], row['Longitude'] = latitude, longitude\n",
    "        row['District'] = [district for district, coords in district_coordinates.items() if coords == (latitude, longitude)][0]\n",
    "\n",
    "    start_time = datetime.now()  # Store the start time\n",
    "\n",
    "    while True:\n",
    "        current_time = datetime.now()\n",
    "\n",
    "        # Check if two hours have passed and update latitude and longitude\n",
    "        if current_time >= start_time + timedelta(hours=2):\n",
    "            for row in csv_data:\n",
    "                latitude, longitude = assign_lat_long(district_coordinates)\n",
    "                row['Latitude'], row['Longitude'] = latitude, longitude\n",
    "                row['District'] = [district for district, coords in district_coordinates.items() if coords == (latitude, longitude)][0]\n",
    "            start_time = current_time  # Reset start time\n",
    "\n",
    "        for csv_row_dict in csv_data:\n",
    "            csv_row_dict['Timestamp'] = current_time\n",
    "\n",
    "            # Remove the '_id' field if it exists in the dictionary\n",
    "            csv_row_dict.pop('_id', None)\n",
    "\n",
    "            # Insert raw data into the 'streaming_data' collection\n",
    "            raw_data_collection.insert_one(csv_row_dict)\n",
    "            response = sagemaker_runtime.invoke_endpoint(\n",
    "            EndpointName='Entry',\n",
    "            ContentType='text/csv',\n",
    "            Body=csv_row_dict\n",
    "            )\n",
    "\n",
    "    # Parse the prediction result from the response\n",
    "            prediction = json.loads(response['Body'].read().decode())\n",
    "            numeric_predictions = prediction  # Replace with your actual numeric predictions\n",
    "\n",
    "            label_predictions = []\n",
    "\n",
    "            for pred in numeric_predictions:\n",
    "                label_disease = disease_mapping.get(int(pred[0]), \"Unknown\")\n",
    "                label_district = district_mapping.get(int(pred[1]), \"Unknown\")\n",
    "                label_medicine_name = medicine_name_mapping.get(int(pred[2]), \"Unknown\")\n",
    "                label_predictions.append([label_disease, label_district, label_medicine_name])\n",
    "\n",
    "            \n",
    "            # Example:\n",
    "            prediction_document = {\n",
    "                **csv_row_dict,\n",
    "                'predicted_disease': label_disease,\n",
    "                'predicted_medicine': label_medicine_name,\n",
    "                'predicted_district': label_district\n",
    "            }\n",
    "            predicted_values_collection.insert_one(prediction_document)\n",
    "\n",
    "            print(f\"Inserted ${prediction_document['predicted_disease']}_${prediction_document['District']}\")\n",
    "\n",
    "            time.sleep(5)  # Wait for 10 seconds\n",
    "\n",
    "generate_and_insert_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc7a6e",
   "metadata": {},
   "source": [
    "### Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce4f6228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted cervical spondylosis__Tan Phu District\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted arthritis__analgesic\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gerd__analgesic\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted migraine__chloramphenicol\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__nasal decongestants\n",
      "Inserted typhoid__penicillin\n",
      "Inserted cervical spondylosis__Tan Phu District\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted arthritis__analgesic\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gerd__analgesic\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted migraine__chloramphenicol\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__nasal decongestants\n",
      "Inserted typhoid__penicillin\n",
      "Inserted gastroenteritis__no medicine\n",
      "Inserted cervical spondylosis__Tan Phu District\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted arthritis__analgesic\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gerd__analgesic\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted migraine__chloramphenicol\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__nasal decongestants\n",
      "Inserted typhoid__penicillin\n",
      "Inserted gastroenteritis__no medicine\n",
      "Inserted gastroenteritis__pepto-bismol,\n",
      "Inserted cervical spondylosis__Tan Phu District\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted arthritis__analgesic\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gerd__analgesic\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted migraine__chloramphenicol\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__nasal decongestants\n",
      "Inserted typhoid__penicillin\n",
      "Inserted gastroenteritis__no medicine\n",
      "Inserted gastroenteritis__pepto-bismol,\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted cervical spondylosis__Tan Phu District\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted arthritis__analgesic\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gerd__analgesic\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted migraine__chloramphenicol\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__nasal decongestants\n",
      "Inserted typhoid__penicillin\n",
      "Inserted gastroenteritis__no medicine\n",
      "Inserted gastroenteritis__pepto-bismol,\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted cervical spondylosis__Tan Phu District\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted arthritis__analgesic\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gerd__analgesic\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted migraine__chloramphenicol\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__nasal decongestants\n",
      "Inserted typhoid__penicillin\n",
      "Inserted gastroenteritis__no medicine\n",
      "Inserted gastroenteritis__pepto-bismol,\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted migraine__nasal decongestants\n",
      "Inserted cervical spondylosis__Tan Phu District\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted arthritis__analgesic\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gerd__analgesic\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted migraine__chloramphenicol\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__nasal decongestants\n",
      "Inserted typhoid__penicillin\n",
      "Inserted gastroenteritis__no medicine\n",
      "Inserted gastroenteritis__pepto-bismol,\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted migraine__nasal decongestants\n",
      "Inserted hepatitis a__chloramphenicol\n",
      "Inserted cervical spondylosis__Tan Phu District\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted arthritis__analgesic\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gerd__analgesic\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted migraine__chloramphenicol\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__nasal decongestants\n",
      "Inserted typhoid__penicillin\n",
      "Inserted gastroenteritis__no medicine\n",
      "Inserted gastroenteritis__pepto-bismol,\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted migraine__nasal decongestants\n",
      "Inserted hepatitis a__chloramphenicol\n",
      "Inserted malaria__chloramphenicol\n",
      "Inserted cervical spondylosis__Tan Phu District\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted arthritis__analgesic\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gerd__analgesic\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted migraine__chloramphenicol\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__nasal decongestants\n",
      "Inserted typhoid__penicillin\n",
      "Inserted gastroenteritis__no medicine\n",
      "Inserted gastroenteritis__pepto-bismol,\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted migraine__nasal decongestants\n",
      "Inserted hepatitis a__chloramphenicol\n",
      "Inserted malaria__chloramphenicol\n",
      "Inserted common cold__nasal decongestants\n",
      "Inserted cervical spondylosis__Tan Phu District\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted fungal infection__chloramphenicol\n",
      "Inserted arthritis__analgesic\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gerd__analgesic\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted migraine__chloramphenicol\n",
      "Inserted gastroenteritis__chloramphenicol\n",
      "Inserted gastroenteritis__Unknown\n",
      "Inserted gastroenteritis__nasal decongestants\n",
      "Inserted typhoid__penicillin\n",
      "Inserted gastroenteritis__no medicine\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 226\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInserted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_document[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_disease\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_document[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_medicine\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    224\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Wait for 10 seconds\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m \u001b[43mgenerate_and_insert_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 220\u001b[0m, in \u001b[0;36mgenerate_and_insert_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m     prediction_document\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: latitude,\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: longitude,\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m: datetime\u001b[38;5;241m.\u001b[39mnow(),\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistrict\u001b[39m\u001b[38;5;124m\"\u001b[39m: district\n\u001b[1;32m    218\u001b[0m     })\n\u001b[1;32m    219\u001b[0m     prediction_document\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 220\u001b[0m     \u001b[43mpredicted_values_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_document\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInserted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_document[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_disease\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_document[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_medicine\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    224\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/collection.py:669\u001b[0m, in \u001b[0;36mCollection.insert_one\u001b[0;34m(self, document, bypass_document_validation, session, comment)\u001b[0m\n\u001b[1;32m    665\u001b[0m     document[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ObjectId()  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m    667\u001b[0m write_concern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_concern_for(session)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m InsertOneResult(\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_insert_one\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mordered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_concern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_concern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbypass_doc_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbypass_document_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    678\u001b[0m     write_concern\u001b[38;5;241m.\u001b[39macknowledged,\n\u001b[1;32m    679\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/collection.py:609\u001b[0m, in \u001b[0;36mCollection._insert_one\u001b[0;34m(self, doc, ordered, write_concern, op_id, bypass_doc_val, session, comment)\u001b[0m\n\u001b[1;32m    597\u001b[0m     result \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcommand(\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__database\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    599\u001b[0m         command,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         retryable_write\u001b[38;5;241m=\u001b[39mretryable_write,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    607\u001b[0m     _check_write_command_response(result)\n\u001b[0;32m--> 609\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__database\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retryable_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43macknowledged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_insert_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc, RawBSONDocument):\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/mongo_client.py:1523\u001b[0m, in \u001b[0;36mMongoClient._retryable_write\u001b[0;34m(self, retryable, func, session, bulk)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute an operation with consecutive retries if possible\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \n\u001b[1;32m   1511\u001b[0m \u001b[38;5;124;03mReturns func()'s return value on success. On error retries the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;124;03m  - `bulk`: bulk abstraction to execute operations in bulk, defaults to None\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tmp_session(session) \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[0;32m-> 1523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_with_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbulk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/mongo_client.py:1421\u001b[0m, in \u001b[0;36mMongoClient._retry_with_session\u001b[0;34m(self, retryable, func, session, bulk)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;66;03m# Ensure that the options supports retry_writes and there is a valid session not in\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;66;03m# transaction, otherwise, we will not support retry behavior for this txn.\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m retryable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\n\u001b[1;32m   1419\u001b[0m     retryable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mretry_writes \u001b[38;5;129;01mand\u001b[39;00m session \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m session\u001b[38;5;241m.\u001b[39min_transaction\n\u001b[1;32m   1420\u001b[0m )\n\u001b[0;32m-> 1421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbulk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbulk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretryable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/_csot.py:107\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/mongo_client.py:1462\u001b[0m, in \u001b[0;36mMongoClient._retry_internal\u001b[0;34m(self, func, session, bulk, is_read, address, read_pref, retryable)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;129m@_csot\u001b[39m\u001b[38;5;241m.\u001b[39mapply\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retry_internal\u001b[39m(\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1437\u001b[0m     retryable: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1438\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Internal retryable helper for all client transactions.\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m \n\u001b[1;32m   1441\u001b[0m \u001b[38;5;124;03m    :Parameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m      Output of the calling func()\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ClientConnectionRetryable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmongo_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbulk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbulk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_read\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_read\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_pref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_pref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretryable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/mongo_client.py:2315\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error(check_csot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_read \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2316\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ServerSelectionTimeoutError:\n\u001b[1;32m   2317\u001b[0m     \u001b[38;5;66;03m# The application may think the write was never attempted\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m     \u001b[38;5;66;03m# if we raise ServerSelectionTimeoutError on the retry\u001b[39;00m\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;66;03m# attempt. Raise the original exception instead.\u001b[39;00m\n\u001b[1;32m   2320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/mongo_client.py:2423\u001b[0m, in \u001b[0;36m_ClientConnectionRetryable._write\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2421\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_last_error()\n\u001b[1;32m   2422\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retryable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 2423\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retryable\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PyMongoError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   2425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retryable:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/collection.py:597\u001b[0m, in \u001b[0;36mCollection._insert_one.<locals>._insert_command\u001b[0;34m(session, conn, retryable_write)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bypass_doc_val:\n\u001b[1;32m    595\u001b[0m     command[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbypassDocumentValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__database\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_concern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_concern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcodec_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__write_response_codec_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__database\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretryable_write\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretryable_write\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m _check_write_command_response(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/helpers.py:322\u001b[0m, in \u001b[0;36m_handle_reauth.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymongo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_reauth:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/pool.py:996\u001b[0m, in \u001b[0;36mConnection.command\u001b[0;34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;66;03m# Catch socket.error, KeyboardInterrupt, etc. and close ourselves.\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m--> 996\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_connection_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/pool.py:968\u001b[0m, in \u001b[0;36mConnection.command\u001b[0;34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_not_writable(unacknowledged)\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcommand\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_mongos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_preference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcodec_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallowable_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlisteners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_bson_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_concern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_write_concern_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_write_concern_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_op_msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop_msg_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m        \u001b[49m\u001b[43munacknowledged\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munacknowledged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexhaust_allowed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexhaust_allowed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_concern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_concern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (OperationFailure, NotPrimaryError):\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/network.py:182\u001b[0m, in \u001b[0;36mcommand\u001b[0;34m(conn, dbname, spec, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed, write_concern)\u001b[0m\n\u001b[1;32m    180\u001b[0m     response_doc: _DocumentOut \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[43mreceive_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     conn\u001b[38;5;241m.\u001b[39mmore_to_come \u001b[38;5;241m=\u001b[39m reply\u001b[38;5;241m.\u001b[39mmore_to_come\n\u001b[1;32m    184\u001b[0m     unpacked_docs \u001b[38;5;241m=\u001b[39m reply\u001b[38;5;241m.\u001b[39munpack_response(\n\u001b[1;32m    185\u001b[0m         codec_options\u001b[38;5;241m=\u001b[39mcodec_options, user_fields\u001b[38;5;241m=\u001b[39muser_fields\n\u001b[1;32m    186\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/network.py:257\u001b[0m, in \u001b[0;36mreceive_message\u001b[0;34m(conn, request_id, max_message_size)\u001b[0m\n\u001b[1;32m    255\u001b[0m         deadline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Ignore the response's request id.\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m length, _, response_to, op_code \u001b[38;5;241m=\u001b[39m _UNPACK_HEADER(\u001b[43m_receive_data_on_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# No request_id for exhaust cursor \"getMore\".\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pymongo/network.py:340\u001b[0m, in \u001b[0;36m_receive_data_on_socket\u001b[0;34m(conn, length, deadline)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _csot\u001b[38;5;241m.\u001b[39mget_timeout() \u001b[38;5;129;01mand\u001b[39;00m deadline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m         conn\u001b[38;5;241m.\u001b[39mset_conn_timeout(\u001b[38;5;28mmax\u001b[39m(deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic(), \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m--> 340\u001b[0m     chunk_length \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbytes_read\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BLOCKING_IO_ERRORS:\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mtimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimed out\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pymongo\n",
    "import time\n",
    "import csv\n",
    "from flask_socketio import emit\n",
    "from faker import Faker\n",
    "from faker.providers import DynamicProvider\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# def predict_and_map_labels(csv_data_bytes):\n",
    "#     # Create a SageMaker runtime client\n",
    "#     sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "# #     csv_data_json = json.dumps(csv_data_bytes)\n",
    "# #     csv_data_bytes = csv_data_json.encode('utf-8')\n",
    "#     # Specify your SageMaker endpoint name\n",
    "#     endpoint_name = 'Entry'  # Replace with your endpoint name\n",
    "\n",
    "#     # Send the CSV data to the SageMaker endpoint for prediction\n",
    "#     response = sagemaker_runtime.invoke_endpoint(\n",
    "#         EndpointName=endpoint_name,\n",
    "#         ContentType='text/csv',\n",
    "#         Body=csv_data_bytes\n",
    "#     )\n",
    "\n",
    "#     # Parse the prediction result from the response\n",
    "#     prediction = json.loads(response['Body'].read().decode())\n",
    "\n",
    "#     # Load the saved label encoders for disease, medicine_name, and district\n",
    "#     disease_mapping = load_label_encoder('disease_mapping.txt')\n",
    "#     medicine_name_mapping = load_label_encoder('medicine_name_mapping.txt')\n",
    "#     district_mapping = load_label_encoder('district_mapping.txt')\n",
    "\n",
    "#     # Convert the numeric predictions to their corresponding labels\n",
    "#     numeric_predictions = prediction  # Replace with your actual numeric predictions\n",
    "#     label_predictions = []\n",
    "\n",
    "#     for pred in numeric_predictions:\n",
    "#         label_disease = disease_mapping.get(int(pred[0]), \"Unknown\")\n",
    "#         label_district = district_mapping.get(int(pred[1]), \"Unknown\")\n",
    "#         label_medicine_name = medicine_name_mapping.get(int(pred[2]), \"Unknown\")\n",
    "#         label_predictions.append([label_disease, label_district, label_medicine_name])\n",
    "\n",
    "#     return label_predictions\n",
    "\n",
    "\n",
    "# List of all column names\n",
    "all_column_names = [\n",
    "    'itching', 'skin_rash', 'nodal_skin_eruptions', 'continuous_sneezing', 'shivering', 'chills', 'joint_pain',\n",
    "    'stomach_pain', 'acidity', 'ulcers_on_tongue', 'muscle_wasting', 'vomiting', 'burning_micturition',\n",
    "    'spotting_ urination', 'fatigue', 'weight_gain', 'anxiety', 'cold_hands_and_feets', 'mood_swings', 'weight_loss',\n",
    "    'restlessness', 'lethargy', 'patches_in_throat', 'irregular_sugar_level', 'cough', 'high_fever', 'sunken_eyes',\n",
    "    'breathlessness', 'sweating', 'dehydration', 'indigestion', 'headache', 'yellowish_skin', 'dark_urine', 'nausea',\n",
    "    'loss_of_appetite', 'pain_behind_the_eyes', 'back_pain', 'constipation', 'abdominal_pain', 'diarrhoea', 'mild_fever',\n",
    "    'yellow_urine', 'yellowing_of_eyes', 'acute_liver_failure', 'fluid_overload', 'swelling_of_stomach',\n",
    "    'swelled_lymph_nodes', 'malaise', 'blurred_and_distorted_vision', 'phlegm', 'throat_irritation', 'redness_of_eyes',\n",
    "    'sinus_pressure', 'runny_nose', 'congestion', 'chest_pain', 'weakness_in_limbs', 'fast_heart_rate',\n",
    "    'pain_during_bowel_movements', 'pain_in_anal_region', 'bloody_stool', 'irritation_in_anus', 'neck_pain', 'dizziness',\n",
    "    'cramps', 'bruising', 'obesity', 'swollen_legs', 'swollen_blood_vessels', 'puffy_face_and_eyes', 'enlarged_thyroid',\n",
    "    'brittle_nails', 'swollen_extremeties', 'excessive_hunger', 'extra_marital_contacts', 'drying_and_tingling_lips',\n",
    "    'slurred_speech', 'knee_pain', 'hip_joint_pain', 'muscle_weakness', 'stiff_neck', 'swelling_joints',\n",
    "    'movement_stiffness', 'spinning_movements', 'loss_of_balance', 'unsteadiness', 'weakness_of_one_body_side',\n",
    "    'loss_of_smell', 'bladder_discomfort', 'foul_smell_of urine', 'continuous_feel_of_urine', 'passage_of_gases',\n",
    "    'internal_itching', 'toxic_look_(typhos)', 'depression', 'irritability', 'muscle_pain', 'altered_sensorium',\n",
    "    'red_spots_over_body', 'belly_pain', 'abnormal_menstruation', 'dischromic _patches', 'watering_from_eyes',\n",
    "    'increased_appetite', 'polyuria', 'family_history', 'mucoid_sputum', 'rusty_sputum', 'lack_of_concentration',\n",
    "    'visual_disturbances', 'receiving_blood_transfusion', 'receiving_unsterile_injections', 'coma', 'stomach_bleeding',\n",
    "    'distention_of_abdomen', 'history_of_alcohol_consumption', 'blood_in_sputum', 'prominent_veins_on_calf',\n",
    "    'palpitations', 'painful_walking', 'pus_filled_pimples', 'blackheads', 'scurring', 'skin_peeling',\n",
    "    'silver_like_dusting', 'small_dents_in_nails', 'inflammatory_nails', 'blister', 'red_sore_around_nose',\n",
    "    'yellow_crust_ooze','District'\n",
    "]\n",
    "\n",
    "mongodb_uri = 'mongodb+srv://saurabh:Solarwind%401@companydata.g6xbxk5.mongodb.net/'\n",
    "# MongoDB database and collection names\n",
    "db_name = 'asm3'\n",
    "\n",
    "\n",
    "# Initialize MongoDB client\n",
    "client = pymongo.MongoClient(mongodb_uri)\n",
    "\n",
    "# Connect to the database\n",
    "db = client[db_name]\n",
    "\n",
    "# Get the collections (create them if they don't exist)\n",
    "raw_data_collection = db[\"test\"]\n",
    "predicted_values_collection = db[\"result\"]\n",
    "\n",
    "fake = Faker()\n",
    "# Function to read CSV and return a list of rows along with column names\n",
    "def read_csv_to_list(csv_file_path):\n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        columns = next(csv_reader)  # Get column names from the first row\n",
    "        data = [dict(zip(columns, row)) for row in csv_reader]  # Create a dict for each row\n",
    "    return columns, data\n",
    "\n",
    "# Function to assign latitude and longitude to a row\n",
    "def assign_lat_long(district_coordinates):\n",
    "    district = random.choice(list(district_coordinates.keys()))\n",
    "    lat_long = district_coordinates[district]\n",
    "    if isinstance(lat_long, tuple) and len(lat_long) == 2:\n",
    "        return lat_long\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid latitude/longitude data for district {district}\")\n",
    "\n",
    "# Function to generate a random symptom data row\n",
    "def generate_symptom_data():\n",
    "    fake = Faker()\n",
    "    \n",
    "    return {symptom: fake.random.randint(0, 1) for symptom in all_column_names}\n",
    "\n",
    "# Function to assign latitude, longitude, and district\n",
    "def assign_location(district_coordinates):\n",
    "    district = random.choice(list(district_coordinates.keys()))\n",
    "    latitude, longitude = district_coordinates[district]\n",
    "    return district, latitude, longitude\n",
    "\n",
    "# Function to generate and insert data into MongoDB\n",
    "def generate_and_insert_data():\n",
    "    district_coordinates = {\n",
    "        'd1': (10.7763897, 106.7011391), 'd2': (10.7763897, 106.7011391),\n",
    "        'd3': (10.7763897, 106.7011391), 'd4': (10.8420693, 106.8277083),\n",
    "        'd5': (10.7763897, 106.7011391), 'd6': (10.7763897, 106.7011391),\n",
    "        'd7': (10.7763897, 106.7011391), 'd8': (10.7763897, 106.7011391),\n",
    "        'd9': (10.7763897, 106.7011391), 'd10': (10.8155799, 106.6257578),\n",
    "        'd11': (10.7008257, 106.7287453), 'd12': (10.815238, 106.6260036),\n",
    "        'Binh Tan District': (10.7703708, 106.5996353),\n",
    "        'Binh Thanh District': (10.8117887, 106.7039109),\n",
    "        'Phu Nhuan District': (10.800981, 106.6794379),\n",
    "        'Tan Binh District': (10.802583, 106.6521157),\n",
    "        'Tan Phu District': (10.7914967, 106.6278431),\n",
    "        'Thu Duc District': (10.82202275, 106.71830155362943)\n",
    "    }\n",
    "\n",
    "    # CSV File Path\n",
    "    csv_file_path = 'dataset_for_simulating_streaming.csv'\n",
    "\n",
    "    # Read the CSV data and get columns\n",
    "    columns, csv_data = read_csv_to_list(csv_file_path)\n",
    "\n",
    "    start_time = datetime.now()  # Store the start time\n",
    "\n",
    "    while True:\n",
    "        current_time = datetime.now()\n",
    "\n",
    "        # Check if two hours have passed and update latitude and longitude\n",
    "        if current_time >= start_time + timedelta(hours=2):\n",
    "            for row in csv_data:\n",
    "                latitude, longitude = assign_lat_long(district_coordinates)\n",
    "                row['Latitude'], row['Longitude'] = latitude, longitude\n",
    "                row['District'] = [district for district, coords in district_coordinates.items() if\n",
    "                                   coords == (latitude, longitude)][0]\n",
    "            start_time = current_time  # Reset start time\n",
    "\n",
    "        for csv_row_dict in csv_data:\n",
    "            csv_row_dict['Timestamp'] = current_time\n",
    "\n",
    "            # Remove the '_id' field if it exists in the dictionary\n",
    "            csv_row_dict.pop('_id', None)\n",
    "\n",
    "            # Generate random symptom data using Faker\n",
    "            fake = Faker()\n",
    "            symptom_data = {symptom: fake.random.randint(0, 1) for symptom in all_column_names}\n",
    "\n",
    "            # Assign random location data\n",
    "            district, latitude, longitude = assign_location(district_coordinates)\n",
    "#             symptom_data.update({\n",
    "#                 \"district\": district,\n",
    "#                 \"latitude\": latitude,\n",
    "#                 \"longitude\": longitude,\n",
    "#                 \"timestamp\": datetime.now()\n",
    "#             })\n",
    "\n",
    "            # Serialize the data to CSV format and encode to bytes\n",
    "            data = pd.DataFrame(symptom_data, index=[0])\n",
    "#             print(data)\n",
    "            csv_data = data.to_csv(index=False, header=False)\n",
    "            csv_data_bytes = csv_data.encode()\n",
    "\n",
    "            # Create a SageMaker runtime client\n",
    "            sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "            # Specify your SageMaker endpoint name\n",
    "            endpoint_name = 'Entry44'  # Replace with your endpoint name\n",
    "\n",
    "            # Send the CSV data to the SageMaker endpoint for prediction\n",
    "            response = sagemaker_runtime.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType='text/csv',\n",
    "                Body=csv_data_bytes\n",
    "            )\n",
    "\n",
    "            # Parse the prediction result from the response\n",
    "            prediction = json.loads(response['Body'].read().decode())\n",
    "\n",
    "            # Insert raw data into the 'streaming_data' collection\n",
    "#             raw_data_collection.insert_one(csv_row_dict)\n",
    "                \n",
    "\n",
    "            for pred in prediction:\n",
    "                label_disease = disease_mapping.get(int(pred[0]), \"Unknown\")\n",
    "                label_medicine_name = medicine_name_mapping.get(int(pred[1]), \"Unknown\")\n",
    "            label_predictions.append([label_disease, label_medicine_name])\n",
    "            # Insert label predictions into the 'result' collection\n",
    "            for label_prediction in label_predictions:\n",
    "                district, latitude, longitude = assign_location(district_coordinates)\n",
    "                prediction_document = {\n",
    "                    **csv_row_dict,\n",
    "                    'predicted_disease': label_prediction[0],\n",
    "                    'predicted_medicine': label_prediction[1],\n",
    "                    \n",
    "                }\n",
    "                prediction_document.update({\n",
    "                    \"latitude\": latitude,\n",
    "                    \"longitude\": longitude,\n",
    "                    \"timestamp\": datetime.now(),\n",
    "                    \"District\": district\n",
    "                })\n",
    "                prediction_document.pop('_id', None)\n",
    "                predicted_values_collection.insert_one(prediction_document)\n",
    "\n",
    "                print(f\"Inserted {prediction_document['predicted_disease']}__{prediction_document['predicted_medicine']}\")\n",
    "\n",
    "            time.sleep(10)  # Wait for 10 seconds\n",
    "\n",
    "generate_and_insert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "404b3a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0,1,0,0,1,1,0,1,1,1,1,0,1,0,0,1,1,0,0,0,1,0,0,0,1,0,1,1,0,1,0,0,0,1,1,1,1,0,1,1,1,0,1,1,0,0,0,1,1,1,0,0,0,1,0,1,1,1,0,0,0,1,1,0,0,1,1,0,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,0,0,0,1,0,1,0,1,1,0,0,0,0,1,0,1,0,1,0,1,1,0,0,1,0,0,1,0,0,0,0,1,1,1,0,0,1,1,0,1,0,1,0,1,1,1,1,0\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d890f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
